import os
import io
import threading
import numpy as np
import sounddevice as sd
import soundfile as sf
import noisereduce as nr
from dotenv import load_dotenv
from openai import OpenAI
import keyboard
import json
import socket
from konlpy.tag import Okt
from parse_command import parse_command_from_keywords  # ë³„ë„ íŒŒì¼ì—ì„œ ëª…ë ¹ í•´ì„

load_dotenv()
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
okt = Okt()

FS = 16000
CHANNELS = 1
is_recording = False
audio_frames = []

UNITY_HOST = '127.0.0.1'
UNITY_PORT = 12345
unity_socket = None

def setup_unity_connection():
    global unity_socket
    try:
        unity_socket = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
        print(f"ğŸ“¡ Unity í†µì‹  ì¤€ë¹„ ì™„ë£Œ - {UNITY_HOST}:{UNITY_PORT}ë¡œ ì „ì†¡í•©ë‹ˆë‹¤")
        return True
    except Exception as e:
        print(f"âŒ Unity ì—°ê²° ì„¤ì • ì‹¤íŒ¨: {e}")
        return False

def audio_callback(indata, frames, time, status):
    if is_recording:
        audio_frames.append(indata.copy())

def extract_keywords_only(text):
    pos_tags = okt.pos(text)
    keywords = [word for word, tag in pos_tags if tag == 'Noun']
    return keywords

def send_to_unity(result_json):
    try:
        json_str = json.dumps(result_json, ensure_ascii=False)
        if unity_socket:
            unity_socket.sendto(json_str.encode('utf-8'), (UNITY_HOST, UNITY_PORT))
            print("ğŸš€ Unityë¡œ ëª…ë ¹ ì „ì†¡ ì™„ë£Œ!", json_str)
        else:
            print("âš ï¸ Unity ì†Œì¼“ì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
    except Exception as e:
        print(f"âŒ Unity ì „ì†¡ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

def transcribe(audio):
    buffer = io.BytesIO()
    sf.write(buffer, audio, FS, format="WAV", subtype="PCM_16")
    buffer.name = "audio.wav"
    buffer.seek(0)

    resp = client.audio.transcriptions.create(
        model="whisper-1",
        file=buffer,
        response_format="json",
        prompt="ë³´ë³‘, ê¶ë³‘, ê¶ìˆ˜, ì ë³´ë³‘, ì ê¶ë³‘, ì ê¶ìˆ˜, ì ê¸°ë³‘, ì ë§ˆë²•ì‚¬, ê¸°ë³‘, ì ê¸°ë³‘, ë§ˆë²•ì‚¬, ê²€ì‚¬, í™œë³‘, ê¸°ë§ˆë³‘, ì „ì§„, ëŒê²©, ì „ë°©, í›„ë°©, ë¹¼, ìœ„ë¡œ, ë’¤ë¡œ, ì •ì§€, ë©ˆì¶°ì¶°"
    )

    text = resp.text.strip()
    print(f"ğŸ“ ì¸ì‹ ê²°ê³¼: {text}")

    keywords = extract_keywords_only(text)
    print("ğŸ”‘ ì¶”ì¶œ í‚¤ì›Œë“œ:", ", ".join(keywords) if keywords else "ì—†ìŒ")

    result_json = parse_command_from_keywords(keywords)
    print("ğŸ“¦ ìµœì¢… ëª…ë ¹ JSON (í•œê¸€):", result_json)

    # í•œê¸€ ë³‘ì¢…ëª… â†’ ì˜ì–´ ë³‘ì¢…ëª… ë³€í™˜
    unit_output_mapping = {
        'ë³´ë³‘': 'infantry',
        'ê¶ë³‘': 'bowman',
        'ê¸°ë³‘': 'cavalry',
        'ë§ˆë²•ì‚¬': 'mage'
    }
    mapped_json = {}
    for k, v in result_json.items():
        if k in ('infantry', 'target') and v in unit_output_mapping:
            mapped_json[k] = unit_output_mapping[v]
        else:
            mapped_json[k] = v
    print("ğŸ“¦ ì „ì†¡í•  ëª…ë ¹ JSON (ì˜ë¬¸):", mapped_json)

    send_to_unity(mapped_json)

def handle_manual_input():
    text = input("ğŸ§¾ ì§ì ‘ ëª…ë ¹ì–´ë¥¼ ì…ë ¥í•˜ì„¸ìš”: ").strip()
    if not text:
        print("âš ï¸ ì…ë ¥ì´ ë¹„ì—ˆìŠµë‹ˆë‹¤.")
        return

    print(f"ğŸ“ ì…ë ¥í•œ í…ìŠ¤íŠ¸: {text}")
    keywords = extract_keywords_only(text)
    print("ğŸ”‘ ì¶”ì¶œ í‚¤ì›Œë“œ:", ", ".join(keywords) if keywords else "ì—†ìŒ")

    result_json = parse_command_from_keywords(keywords)
    print("ğŸ“¦ ìµœì¢… ëª…ë ¹ JSON (í•œê¸€):", result_json)

    # í•œê¸€ ë³‘ì¢…ëª… â†’ ì˜ì–´ ë³‘ì¢…ëª… ë³€í™˜
    unit_output_mapping = {
        'ë³´ë³‘': 'infantry',
        'ê¶ë³‘': 'bowman',
        'ê¸°ë³‘': 'cavalry',
        'ë§ˆë²•ì‚¬': 'mage'
    }
    mapped_json = {}
    for k, v in result_json.items():
        if k in ('infantry', 'target') and v in unit_output_mapping:
            mapped_json[k] = unit_output_mapping[v]
        else:
            mapped_json[k] = v
    print("ğŸ“¦ ì „ì†¡í•  ëª…ë ¹ JSON (ì˜ë¬¸):", mapped_json)

    send_to_unity(mapped_json)

def record_control():
    global is_recording, audio_frames

    print("âºï¸ ìŠ¤í˜ì´ìŠ¤ë°”ë¥¼ ëˆ„ë¥´ë©´ ë…¹ìŒ ì‹œì‘ / ì¢…ë£Œí•©ë‹ˆë‹¤. (Ctrl+Cë¡œ ì¢…ë£Œ)")
    print("âŒ¨ï¸ v í‚¤ë¥¼ ëˆ„ë¥´ë©´ í…ìŠ¤íŠ¸ë¥¼ ì§ì ‘ ì…ë ¥í•˜ì—¬ ëª…ë ¹ì„ ì „ì†¡í•©ë‹ˆë‹¤.")
    with sd.InputStream(samplerate=FS, channels=CHANNELS, dtype='int16', callback=audio_callback):
        while True:
            event = keyboard.read_event()
            if event.event_type == keyboard.KEY_DOWN:
                if event.name == 'space':
                    if not is_recording:
                        print("â–¶ ë…¹ìŒ ì‹œì‘!")
                        is_recording = True
                        audio_frames = []
                    else:
                        print("â¹ï¸ ë…¹ìŒ ì¤‘ì§€!")
                        is_recording = False
                        if audio_frames:
                            audio = np.concatenate(audio_frames, axis=0)
                            audio_flat = audio.flatten()
                            reduced_audio = nr.reduce_noise(y=audio_flat, sr=FS)
                            reduced_audio = reduced_audio.reshape(-1, 1)
                            threading.Thread(target=transcribe, args=(reduced_audio,)).start()
                elif event.name == 'v':
                    handle_manual_input()

def main():
    try:
        setup_unity_connection()
        record_control()
    except KeyboardInterrupt:
        print("\nğŸ›‘ ì¢…ë£Œí•©ë‹ˆë‹¤. ì•ˆë…•!")
    finally:
        if unity_socket:
            unity_socket.close()
            print("ğŸ”Œ Unity ì—°ê²°ì„ ë‹«ì•˜ìŠµë‹ˆë‹¤")

if __name__ == "__main__":
    main()
